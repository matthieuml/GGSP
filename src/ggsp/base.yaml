exp_path: ./run
exp_name: GIN_augmented
user: MML # User used for submission to Google Drive (default: Anonymous)

# =========== Dataset parameters ===========

dataset_folder: ./data
training_dataset: train_augmented
valid_dataset: valid
test_dataset: test
dataset_preprocessing_function: base_preprocess_dataset # Function to preprocess the dataset (default: base_preprocess_dataset)
n_max_nodes: 50 # Possible maximum number of nodes in graphs (default: 50)
spectral_emb_dim: 10 # Dimensionality of spectral embeddings for representing graph structures (default: 10)
shuffle_train: True 
shuffle_val: False
shuffle_test: False # Should be always False to fit submission format


# =========== Models ===========
seed: 42 # Seed for random number generators, fixing the randomness in the application (default: 42)

# VAE model parameters
encoder_classname: GIN # Encoder class name for the VAE model (default: GIN)
decoder_classname: Decoder # Decoder class name for the VAE model (default: Decoder)
hidden_dim_encoder: 144 # Hidden dimension size for encoder layers (default: 64)
hidden_dim_decoder: 353 # Hidden dimension size for decoder layers (default: 256)
latent_dim: 18 # Dimensionality of the latent space in the autoencoder (default: 32)
n_layers_encoder: 4 # Number of layers in the encoder network (default: 2)
n_layers_decoder: 5 # Number of layers in the decoder network (default: 3)

# VAE training parameters
train_autoencoder: True # Whether to train the VAE model
epochs_autoencoder: 1000 # Number of training epochs for the autoencoder (default: 200)
batch_size_autoencoder: 128 # Batch size for training, controlling the number of samples per gradient update (default: 128)
vae_lr: 0.001 # Learning rate for the VAE optimizer, typically a small float value (default: 0.001)
vae_scheduler_step_size: 500 # Period of learning rate decay for the VAE optimizer (default: 500)
contrastive_loss_k: 2 # Coefficient for the contrastive loss in the VAE loss function (default: 0)
vae_temperature_contrastive: 0.07 # Temperature parameter for the contrastive loss in the VAE loss function (default: 0.07)
vae_contrastive_weight: 1.0e-03 # Weight of the contrastive loss in the VAE loss function (default: 1e-03)
vae_scheduler_gamma: 0.1 # Multiplicative factor of learning rate decay for the VAE optimizer (default: 0.1)
vae_kld_weight: 3.5e-8 # Weight of the KLD loss in the VAE loss function (default: 0.05)
is_kld_weight_adaptative: False # Whether to adapt the KLD weight during training (default: False)
vae_load_checkpoint_path: null # Path to a checkpoint to load the model from (can restart training from)
vae_save_checkpoint: True # Whether to save the VAE model checkpoint (default: True)

# Diffusion parameters
timesteps: 500 # Number of timesteps for the diffusion (default: 500)
hidden_dim_denoise: 512 # Hidden dimension size for denoising model layers (default: 512)
n_layers_denoise: 3 # Number of layers in the denoising model (default: 3)
n_condition: 8 # Number of distinct condition properties used in conditional vector (default: 7)
dim_condition: 128 # Dimensionality of conditioning vectors for conditional generation (default: 128)

# Diffusion training parameters
train_denoise: True # Whether to train the diffusion model (default: True)
epochs_denoise: 1000 # Number of training epochs for the denoising model (default: 100)
batch_size_denoise: 128 # Batch size for training, controlling the number of samples per gradient update (default: 256)
noising_schedule_function: linear_beta_schedule # Function to schedule the noise level during training (default: linear_beta_schedule)
denoise_loss_type: huber # Loss function type for the denoising model (default: huber)
denoise_lr: 0.001 # Learning rate for the denoising model optimizer, typically a small float value (default: 0.001)
denoise_scheduler_step_size: 500 # Period of learning rate decay for the denoising model optimizer (default: 500)
vae_scheduler_gamma: 0.1 # Multiplicative factor of learning rate decay for the denoising model optimizer (default: 0.1)
denoise_load_checkpoint_path: null # Path to a checkpoint to load the model from and restart training
denoise_save_checkpoint: True # Whether to save the denoising model checkpoint (default: True)


# =========== Evaluation ===========
submission_file: True # Whether to generate a submission file computing the MAE in the process (default: True)
upload_submission_file: False # Whether to upload the submission file to Google Drive when generated (default: False)
graph_metric: MAE # Metric used to compute the distance between graphs can be None for no computing (default: MAE)


# =========== Logging ===========
verbose: True # Whether to print additional information during training and evaluation (default: True)
save_logs: True # Whether to save logs during training and evaluation (default: True)
log_level: INFO # Logging level for the application (default: INFO)
